{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasra-sal/Password_Strength/blob/main/Password_Stength.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "krd9sKsD3BVS",
        "outputId": "569701b0-f0e0-400a-f70a-4d4f812d9a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "b'Skipping line 2810: expected 2 fields, saw 5\\nSkipping line 4641: expected 2 fields, saw 5\\nSkipping line 7171: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 11220: expected 2 fields, saw 5\\nSkipping line 13809: expected 2 fields, saw 5\\nSkipping line 14132: expected 2 fields, saw 5\\nSkipping line 14293: expected 2 fields, saw 5\\nSkipping line 14865: expected 2 fields, saw 5\\nSkipping line 17419: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 22801: expected 2 fields, saw 5\\nSkipping line 25001: expected 2 fields, saw 5\\nSkipping line 26603: expected 2 fields, saw 5\\nSkipping line 26742: expected 2 fields, saw 5\\nSkipping line 29702: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 32767: expected 2 fields, saw 5\\nSkipping line 32878: expected 2 fields, saw 5\\nSkipping line 35643: expected 2 fields, saw 5\\nSkipping line 36550: expected 2 fields, saw 5\\nSkipping line 38732: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 40567: expected 2 fields, saw 5\\nSkipping line 40576: expected 2 fields, saw 5\\nSkipping line 41864: expected 2 fields, saw 5\\nSkipping line 46861: expected 2 fields, saw 5\\nSkipping line 47939: expected 2 fields, saw 5\\nSkipping line 48628: expected 2 fields, saw 5\\nSkipping line 48908: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 57582: expected 2 fields, saw 5\\nSkipping line 58782: expected 2 fields, saw 5\\nSkipping line 58984: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 61518: expected 2 fields, saw 5\\nSkipping line 63451: expected 2 fields, saw 5\\nSkipping line 68141: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 72083: expected 2 fields, saw 5\\nSkipping line 74027: expected 2 fields, saw 5\\nSkipping line 77811: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 83958: expected 2 fields, saw 5\\nSkipping line 85295: expected 2 fields, saw 5\\nSkipping line 88665: expected 2 fields, saw 5\\nSkipping line 89198: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 92499: expected 2 fields, saw 5\\nSkipping line 92751: expected 2 fields, saw 5\\nSkipping line 93689: expected 2 fields, saw 5\\nSkipping line 94776: expected 2 fields, saw 5\\nSkipping line 97334: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 102316: expected 2 fields, saw 5\\nSkipping line 103421: expected 2 fields, saw 5\\nSkipping line 106872: expected 2 fields, saw 5\\nSkipping line 109363: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 110117: expected 2 fields, saw 5\\nSkipping line 110465: expected 2 fields, saw 5\\nSkipping line 113843: expected 2 fields, saw 5\\nSkipping line 115634: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 121518: expected 2 fields, saw 5\\nSkipping line 123692: expected 2 fields, saw 5\\nSkipping line 124708: expected 2 fields, saw 5\\nSkipping line 129608: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 133176: expected 2 fields, saw 5\\nSkipping line 135532: expected 2 fields, saw 5\\nSkipping line 138042: expected 2 fields, saw 5\\nSkipping line 139485: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 140401: expected 2 fields, saw 5\\nSkipping line 144093: expected 2 fields, saw 5\\nSkipping line 149850: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 151831: expected 2 fields, saw 5\\nSkipping line 158014: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 162047: expected 2 fields, saw 5\\nSkipping line 164515: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 170313: expected 2 fields, saw 5\\nSkipping line 171325: expected 2 fields, saw 5\\nSkipping line 171424: expected 2 fields, saw 5\\nSkipping line 175920: expected 2 fields, saw 5\\nSkipping line 176210: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 183603: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 190264: expected 2 fields, saw 5\\nSkipping line 191683: expected 2 fields, saw 5\\nSkipping line 191988: expected 2 fields, saw 5\\nSkipping line 195450: expected 2 fields, saw 5\\nSkipping line 195754: expected 2 fields, saw 5\\nSkipping line 197124: expected 2 fields, saw 5\\nSkipping line 199263: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 202603: expected 2 fields, saw 5\\nSkipping line 209960: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 213218: expected 2 fields, saw 5\\nSkipping line 217060: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 220121: expected 2 fields, saw 5\\nSkipping line 223518: expected 2 fields, saw 5\\nSkipping line 226293: expected 2 fields, saw 5\\nSkipping line 227035: expected 2 fields, saw 7\\nSkipping line 227341: expected 2 fields, saw 5\\nSkipping line 227808: expected 2 fields, saw 5\\nSkipping line 228516: expected 2 fields, saw 5\\nSkipping line 228733: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 232043: expected 2 fields, saw 5\\nSkipping line 232426: expected 2 fields, saw 5\\nSkipping line 234490: expected 2 fields, saw 5\\nSkipping line 239626: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 240461: expected 2 fields, saw 5\\nSkipping line 244518: expected 2 fields, saw 5\\nSkipping line 245395: expected 2 fields, saw 5\\nSkipping line 246168: expected 2 fields, saw 5\\nSkipping line 246655: expected 2 fields, saw 5\\nSkipping line 246752: expected 2 fields, saw 5\\nSkipping line 247189: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 250276: expected 2 fields, saw 5\\nSkipping line 255327: expected 2 fields, saw 5\\nSkipping line 257094: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 264626: expected 2 fields, saw 5\\nSkipping line 265028: expected 2 fields, saw 5\\nSkipping line 269150: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 271360: expected 2 fields, saw 5\\nSkipping line 273975: expected 2 fields, saw 5\\nSkipping line 274742: expected 2 fields, saw 5\\nSkipping line 276227: expected 2 fields, saw 5\\nSkipping line 279807: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 283425: expected 2 fields, saw 5\\nSkipping line 287468: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 292995: expected 2 fields, saw 5\\nSkipping line 293496: expected 2 fields, saw 5\\nSkipping line 293735: expected 2 fields, saw 5\\nSkipping line 295060: expected 2 fields, saw 5\\nSkipping line 296643: expected 2 fields, saw 5\\nSkipping line 296848: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 308926: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 310360: expected 2 fields, saw 5\\nSkipping line 317004: expected 2 fields, saw 5\\nSkipping line 318207: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 331783: expected 2 fields, saw 5\\nSkipping line 333864: expected 2 fields, saw 5\\nSkipping line 335958: expected 2 fields, saw 5\\nSkipping line 336290: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 343526: expected 2 fields, saw 5\\nSkipping line 343857: expected 2 fields, saw 5\\nSkipping line 344059: expected 2 fields, saw 5\\nSkipping line 348691: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 353446: expected 2 fields, saw 5\\nSkipping line 357073: expected 2 fields, saw 5\\nSkipping line 359753: expected 2 fields, saw 5\\nSkipping line 359974: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 366534: expected 2 fields, saw 5\\nSkipping line 369514: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 377759: expected 2 fields, saw 5\\nSkipping line 379327: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 380769: expected 2 fields, saw 5\\nSkipping line 381073: expected 2 fields, saw 5\\nSkipping line 381489: expected 2 fields, saw 5\\nSkipping line 386304: expected 2 fields, saw 5\\nSkipping line 387635: expected 2 fields, saw 5\\nSkipping line 389613: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 392604: expected 2 fields, saw 5\\nSkipping line 393184: expected 2 fields, saw 5\\nSkipping line 395530: expected 2 fields, saw 5\\nSkipping line 396939: expected 2 fields, saw 5\\nSkipping line 397385: expected 2 fields, saw 5\\nSkipping line 397509: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 402902: expected 2 fields, saw 5\\nSkipping line 405187: expected 2 fields, saw 5\\nSkipping line 408412: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 419423: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 420962: expected 2 fields, saw 5\\nSkipping line 425965: expected 2 fields, saw 5\\nSkipping line 427496: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 438881: expected 2 fields, saw 5\\nSkipping line 439776: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 440345: expected 2 fields, saw 5\\nSkipping line 445507: expected 2 fields, saw 5\\nSkipping line 445548: expected 2 fields, saw 5\\nSkipping line 447184: expected 2 fields, saw 5\\nSkipping line 448603: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 451732: expected 2 fields, saw 5\\nSkipping line 458249: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 460274: expected 2 fields, saw 5\\nSkipping line 467630: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 473961: expected 2 fields, saw 5\\nSkipping line 476281: expected 2 fields, saw 5\\nSkipping line 478010: expected 2 fields, saw 5\\nSkipping line 478322: expected 2 fields, saw 5\\nSkipping line 479999: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 480898: expected 2 fields, saw 5\\nSkipping line 481688: expected 2 fields, saw 5\\nSkipping line 485193: expected 2 fields, saw 5\\nSkipping line 485519: expected 2 fields, saw 5\\nSkipping line 486000: expected 2 fields, saw 5\\nSkipping line 489063: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 494525: expected 2 fields, saw 5\\nSkipping line 495009: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 501954: expected 2 fields, saw 5\\nSkipping line 508035: expected 2 fields, saw 5\\nSkipping line 508828: expected 2 fields, saw 5\\nSkipping line 509833: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 510410: expected 2 fields, saw 5\\nSkipping line 518229: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 520302: expected 2 fields, saw 5\\nSkipping line 520340: expected 2 fields, saw 5\\nSkipping line 525174: expected 2 fields, saw 5\\nSkipping line 526251: expected 2 fields, saw 5\\nSkipping line 529611: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 531398: expected 2 fields, saw 5\\nSkipping line 534146: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 544954: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 553002: expected 2 fields, saw 5\\nSkipping line 553883: expected 2 fields, saw 5\\nSkipping line 553887: expected 2 fields, saw 5\\nSkipping line 553915: expected 2 fields, saw 5\\nSkipping line 554172: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 563534: expected 2 fields, saw 5\\nSkipping line 565191: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 574108: expected 2 fields, saw 5\\nSkipping line 574412: expected 2 fields, saw 5\\nSkipping line 575985: expected 2 fields, saw 5\\nSkipping line 580091: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 582682: expected 2 fields, saw 5\\nSkipping line 585885: expected 2 fields, saw 5\\nSkipping line 590171: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 591924: expected 2 fields, saw 5\\nSkipping line 592515: expected 2 fields, saw 5\\nSkipping line 593888: expected 2 fields, saw 5\\nSkipping line 596245: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 607344: expected 2 fields, saw 5\\nSkipping line 607633: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 610939: expected 2 fields, saw 5\\nSkipping line 613638: expected 2 fields, saw 5\\nSkipping line 615643: expected 2 fields, saw 5\\nSkipping line 615901: expected 2 fields, saw 5\\nSkipping line 617389: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 634641: expected 2 fields, saw 5\\nSkipping line 635755: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 646243: expected 2 fields, saw 5\\nSkipping line 647165: expected 2 fields, saw 5\\nSkipping line 648610: expected 2 fields, saw 5\\nSkipping line 648772: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 651833: expected 2 fields, saw 5\\nSkipping line 653663: expected 2 fields, saw 5\\nSkipping line 656233: expected 2 fields, saw 5\\nSkipping line 656694: expected 2 fields, saw 5\\nSkipping line 659783: expected 2 fields, saw 5\\n'\n",
            "b'Skipping line 660478: expected 2 fields, saw 5\\nSkipping line 661133: expected 2 fields, saw 5\\nSkipping line 661736: expected 2 fields, saw 5\\nSkipping line 669827: expected 2 fields, saw 5\\n'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      password  strength\n",
              "0     kzde5577         1\n",
              "1     kino3434         1\n",
              "2    visi7k1yr         1\n",
              "3     megzy123         1\n",
              "4  lamborghin1         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e55ae03-ffca-46f0-9ef2-48831238ed55\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>password</th>\n",
              "      <th>strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kzde5577</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kino3434</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>visi7k1yr</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>megzy123</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lamborghin1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e55ae03-ffca-46f0-9ef2-48831238ed55')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e55ae03-ffca-46f0-9ef2-48831238ed55 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e55ae03-ffca-46f0-9ef2-48831238ed55');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import pickle\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import keras \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten,Dense,Dropout,BatchNormalization\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import decomposition, datasets\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD, PCA\n",
        "from sklearn import preprocessing, neighbors\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models\n",
        "from keras.utils import plot_model\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/kasra-sal/Password_Strength/main/data.csv\"\n",
        "data = pd.read_csv(url, error_bad_lines=False,chunksize=10000,iterator=True)\n",
        "data = pd.concat(data,ignore_index=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_F7GKvjkAKL",
        "outputId": "74aa62ed-0730-4769-8e67-914f237fdb97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
            "  libgvc6-plugins-gtk libxdot4\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libgvc6-plugins-gtk libxdot4\n",
            "0 upgraded, 8 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 2,120 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libxdot4 amd64 2.40.1-2 [15.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6-plugins-gtk amd64 2.40.1-2 [18.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgraphviz-dev amd64 2.40.1-2 [57.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Fetched 2,120 kB in 0s (14.3 MB/s)\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../1-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../2-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../3-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libxdot4.\n",
            "Preparing to unpack .../4-libxdot4_2.40.1-2_amd64.deb ...\n",
            "Unpacking libxdot4 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvc6-plugins-gtk.\n",
            "Preparing to unpack .../5-libgvc6-plugins-gtk_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvc6-plugins-gtk (2.40.1-2) ...\n",
            "Selecting previously unselected package libgraphviz-dev.\n",
            "Preparing to unpack .../6-libgraphviz-dev_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgraphviz-dev (2.40.1-2) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../7-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libxdot4 (2.40.1-2) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgvc6-plugins-gtk (2.40.1-2) ...\n",
            "Setting up libgraphviz-dev (2.40.1-2) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygraphviz\n",
            "  Downloading pygraphviz-1.10.zip (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.6/120.6 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygraphviz: filename=pygraphviz-1.10-cp38-cp38-linux_x86_64.whl size=167644 sha256=c882b4c259c7d5790de7716da1e2f5cb3a6ca8f313d45af314818a58bdfa64af\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/bd/46/118c2a336c6fd8d47026854302f8fad63bb7e431e52008ea06\n",
            "Successfully built pygraphviz\n",
            "Installing collected packages: pygraphviz\n",
            "Successfully installed pygraphviz-1.10\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting snapml\n",
            "  Downloading snapml-1.11.1-cp38-cp38-manylinux2014_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from snapml) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from snapml) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from snapml) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->snapml) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->snapml) (3.1.0)\n",
            "Installing collected packages: snapml\n",
            "Successfully installed snapml-1.11.1\n"
          ]
        }
      ],
      "source": [
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz\n",
        "!pip install -q -U keras-tuner\n",
        "!pip install snapml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "D3GyxnGxDBhy",
        "outputId": "9e4d5cf6-cfe0-496c-8d2d-2d6f035cb8a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc98d3c3f40>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(data['strength'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "v5skWrlBlyTs"
      },
      "outputs": [],
      "source": [
        "weak = data[data['strength']==0]\n",
        "medium = data[data['strength']==1]\n",
        "strong = data[data['strength']==2]\n",
        "\n",
        "\n",
        "def data_downsampling(x):\n",
        "  downsample = resample(x,replace=True,n_samples=len(weak),random_state=42)\n",
        "  return downsample \n",
        "\n",
        "medium_resample = data_downsampling(medium)\n",
        "strong_resample = data_downsampling(strong)\n",
        "\n",
        "data = pd.concat([weak,medium_resample,strong_resample])\n",
        "\n",
        "# Data cleaning\n",
        "data.isna().sum()\n",
        "\n",
        "# Drop empty rows\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "\n",
        "# Preparing data \n",
        "data['length'] = data['password'].str.len()\n",
        "def createTokens(f):\n",
        "    tokens = []\n",
        "    for i in f:\n",
        "        tokens.append(i)\n",
        "    return tokens\n",
        "\n",
        "# data preperation and Training/Testing split\n",
        "\n",
        "\n",
        "X = np.array(data[\"password\"])\n",
        "y = np.array(data['strength'])\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=createTokens)\n",
        "X = vectorizer.fit_transform(X)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "X_train =X_train.toarray()\n",
        "X_test = X_test.toarray()\n",
        "\n",
        "\n",
        "\n",
        "list_of_pass = ['asjkgsSa!1@','R3C0V3R3NDL3SSa!','sasDddas','keisA!nF@#dy']\n",
        "vectorized_pass = vectorizer.transform(list_of_pass)\n",
        "vectorized_pass = vectorized_pass.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "2elywoIh4aaI",
        "outputId": "540bb40b-f78e-47fa-f095-33b80de6b9c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc918ceec40>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "sns.countplot(data['strength'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "_xO_eh0Sd0wi"
      },
      "outputs": [],
      "source": [
        "\n",
        "class pipe_model():\n",
        "  def __init__(self,X_train,y_train, X_test,y_test,pipe_filename,filename):\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "    self.filename = filename\n",
        "    self.pipe_filename = pipe_filename\n",
        "    self.model = self.pipe_filename.fit(self.X_train,self.y_train)\n",
        "\n",
        "  def pipe_model(self):\n",
        "    return self.model\n",
        "  \n",
        "  def model_score(self):\n",
        "    score = self.pipe_filename.score(self.X_test,self.y_test)\n",
        "    return(score*100)\n",
        "\n",
        "  def predict(self):\n",
        "    return self.model.predict(self.X_test)\n",
        "\n",
        "  def model_save(self,filename):\n",
        "    filename = f'{self.filename}.sav'\n",
        "    pickle.dump(pipeline, open(filename, 'wb'))\n",
        "\n",
        "  def model_load(self,filename):\n",
        "    model = pickle.load(open(f'{self.filename}.sav', 'rb'))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "class DNN_model():\n",
        "  def __init__(self,epoch,max_epoch,batch_size,Flatten_shape,act_1,act_2,act_3,act_out,min_val,max_val):\n",
        "    self.epoch = epoch\n",
        "    self.max_epoch = max_epoch\n",
        "    self.batch_size = batch_size\n",
        "    self.Flatten_shape = Flatten_shape\n",
        "    self.act_1 = act_1\n",
        "    self.act_2 = act_2\n",
        "    self.act_3 = act_3\n",
        "    self.act_out = act_out\n",
        "    self.min_val = min_val\n",
        "    self.max_val = max_val\n",
        "    self.DNN_optimizer\n",
        "    self.DNN_manual_model\n",
        "    self.DNN_best_estimate\n",
        "\n",
        "  def DNN_optimizer(self,x):\n",
        "    # Tune the number of units in the two hidden layers:\n",
        "    unit_1 = x.Int('units_1', min_value = self.min_val, max_value = self.max_val, step = 32)\n",
        "    unit_2 = x.Int('units_2', min_value = self.min_val, max_value = self.max_val, step = 32)\n",
        "    unit_3 = x.Int('units_3', min_value = self.min_val, max_value = self.max_val, step = 32)\n",
        "\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape= [self.Flatten_shape]),\n",
        "        Dense(units = unit_1,activation=self.act_1),\n",
        "        BatchNormalization(),\n",
        "        Dense(units = unit_2,activation=self.act_2),\n",
        "        BatchNormalization(),\n",
        "        Dense(units = unit_3,activation=self.act_3),\n",
        "        Dense(3,activation=self.act_out)\n",
        "      ])\n",
        "    # Tune the optimizer:\n",
        "    x_optimizer = x.Choice('optimizer', ['Adam', 'RMSProp', 'SGD', 'Adagrad', 'Adamax'])\n",
        "    model.compile(optimizer = x_optimizer,\n",
        "                  loss =\"sparse_categorical_crossentropy\", \n",
        "                  metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def DNN_best_estimate(self):\n",
        "    tuner = kt.Hyperband(self.DNN_optimizer, objective = 'val_accuracy',max_epochs = self.max_epoch, factor = 3, overwrite = True)\n",
        "    tuner.search(X_train, y_train,validation_data=(X_test, y_test), verbose=1,batch_size=self.batch_size)\n",
        "    optimized_model = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "    model = tuner.hypermodel.build(optimized_model)\n",
        "    history =  model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=self.epoch,verbose=1,batch_size=self.batch_size)\n",
        "    #model.save(\"DNN_best_estimate\")\n",
        "    return history\n",
        "\n",
        "  def DNN_manual_model(self):\n",
        "      model = Sequential([\n",
        "        Flatten(input_shape=[self.Flatten_shape]),\n",
        "        Dense(416,activation=self.act_1),\n",
        "        BatchNormalization(),\n",
        "        Dense(128,activation=self.act_2),\n",
        "        BatchNormalization(),\n",
        "        Dense(100,activation=self.act_3),\n",
        "        Dense(3,activation=self.act_out)\n",
        "      ])\n",
        "      model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                    optimizer='Adam',\n",
        "                    metrics=[\"accuracy\"])\n",
        "\n",
        "      history = model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=self.epoch, verbose=0,batch_size=self.batch_size)\n",
        "      #model.save(\"DNN_manual_model\")\n",
        "      filename = 'DNN_best_estimate.sav'\n",
        "      pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "      return history, model\n",
        "\n",
        "  def DNN_score(self,model):\n",
        "      test_score = model.evaluate(X_test,y_test,verbose=0,batch_size = 1000) \n",
        "      test_metric = model.metrics_names[1]\n",
        "      text = print(f\"Test {test_metric} is : {test_score[1]*100} \\n\")\n",
        "\n",
        "  def DNN_graph_model(self,history):\n",
        "        pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "        plt.grid(True)\n",
        "        plt.gca().set_ylim(0, 1)\n",
        "        plt.show()\n",
        "\n",
        "  def DNN_predict(self,model,list_to_predict):\n",
        "        predict = model.predict(list_to_predict,verbose=1)\n",
        "        output = np.argmax((predict), axis = 1)\n",
        "        return output\n",
        "\n",
        "def confusionMatrix(y_test,y_pred,model):\n",
        "    cm = confusion_matrix(y_test,y_pred,labels=model.classes_)\n",
        "    pcm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "    pcm.plot()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "4FuGWxhb2uHO"
      },
      "outputs": [],
      "source": [
        "class pipe_model():\n",
        "  def __init__(self,X_train,y_train,X_test,y_test):\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.X_test = X_test  \n",
        "    self.y_test = y_test\n",
        "\n",
        "  def fit(self,pipe_filename):\n",
        "    model = pipe_filename.fit(self.X_train,self.y_train)\n",
        "    return model\n",
        "  def model_score(self,model,X_test,y_test):\n",
        "    score = model.score(self.X_test,self.y_test)\n",
        "    return(score*100)\n",
        "\n",
        "  def predict(self,model,X_test):\n",
        "    return model.predict(X_test)\n",
        "\n",
        "  def save(self,filename):\n",
        "    model = self.model\n",
        "    pickle.dump(model, open( f'{filename}.sav', 'wb'))\n",
        "\n",
        "  def load(self,filename):\n",
        "    model = pickle.load(open(f'{filename}.sav', 'rb'))\n",
        "    return model\n",
        " \n",
        "\n",
        "class ANN:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.model = Sequential()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "\n",
        "    def add_layer(self, units, activation, input_size=None):\n",
        "        if input_size == True:\n",
        "            self.model.add(Flatten(input_shape=[self.input_size]))\n",
        "            self.model.add(Dense(units, activation=activation))\n",
        "        else:\n",
        "            self.model.add(Dense(units,activation=activation))\n",
        "    def Batch_normalization(self):\n",
        "        self.model.add(BatchNormalization())\n",
        "        \n",
        "    def compile(self, optimizer, loss, metrics):\n",
        "        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    def summary(self):\n",
        "        return self.model.summary()\n",
        "\n",
        "    def predict(self,model,list_to_predict):\n",
        "        predict = model.predict(list_to_predict,verbose=0)\n",
        "        output = np.argmax((predict), axis = 1)\n",
        "        return output\n",
        "\n",
        "    def model_getter(self):\n",
        "      return self.model\n",
        "   \n",
        "    def fit(self, X_train, y_train, epochs, batch_size, validation_data=None):\n",
        "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
        "\n",
        "    def evaluate(self, x, y):\n",
        "        return self.model.evaluate(x, y)\n",
        "\n",
        "    def save(self, file_):\n",
        "        self.model.save(file_)\n",
        "    \n",
        "    def load(self, file_):\n",
        "        model = keras.models.load_model(file_)\n",
        "        return model\n",
        "\n",
        "\n",
        "class optimizer():\n",
        "  def __init__(self,X_train,y_train,X_test,y_test):\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "  def optimize_ANN(self,epoch,max_epoch,batch_size,min_val,max_val,Flatten_shape,act_1,act_2,act_3,act_out):\n",
        "    def DNN_optimizer(self,x):\n",
        "      # Tune the number of units in the two hidden layers:\n",
        "      unit_1 = x.Int('units_1', min_value = min_val, max_value = max_val, step = 32)\n",
        "      unit_2 = x.Int('units_2', min_value = min_val, max_value = max_val, step = 32)\n",
        "      unit_3 = x.Int('units_3', min_value = min_val, max_value = max_val, step = 32)\n",
        "\n",
        "      model = Sequential([\n",
        "          Flatten(input_shape= [Flatten_shape]),\n",
        "          Dense(units = unit_1,activation=act_1),\n",
        "          BatchNormalization(),\n",
        "          Dense(units = unit_2,activation=act_2),\n",
        "          BatchNormalization(),\n",
        "          Dense(units = unit_3,activation=act_3),\n",
        "          Dense(3,activation=act_out)\n",
        "        ])\n",
        "      # Tune the optimizer:\n",
        "      x_optimizer = x.Choice('optimizer', ['Adam', 'RMSProp', 'SGD', 'Adagrad', 'Adamax'])\n",
        "      model.compile(optimizer = x_optimizer,\n",
        "                    loss =\"sparse_categorical_crossentropy\", \n",
        "                    metrics = ['accuracy'])\n",
        "      return model\n",
        "\n",
        "    tuner = kt.Hyperband(DNN_optimizer, objective = 'val_accuracy',max_epochs = max_epoch, factor = 3, overwrite = True)\n",
        "    tuner.search(X_train, y_train,validation_data=(X_test, y_test), verbose=1,batch_size=batch_size)\n",
        "    optimized_model = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "    model = tuner.hypermodel.build(optimized_model)\n",
        "    history =  model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=epoch,verbose=1,batch_size=batch_size)\n",
        "    #model.save(\"DNN_best_estimate\")\n",
        "    return history\n",
        "  def DCT_optimizer(self,model,criterion,max_depth,sample_leaf,sample_split):\n",
        "    pipe = Pipeline(steps=[(\"model\", model)])\n",
        "    param = {\"model__criterion\":criterion,\n",
        "            \"model__max_depth\":max_depth,\n",
        "            \"model__min_samples_split\":sample_split,\n",
        "            \"model__min_samples_leaf\":sample_leaf,\n",
        "            }\n",
        "    _grid = GridSearchCV(estimator=pipe, param_grid=param, verbose=True)\n",
        "    pipe.get_params().keys()\n",
        "    _grid.fit(X_train,y_train)\n",
        "\n",
        "    return _grid.best_estimator_\n",
        "\n",
        "  def RFT_optimizer(self,max_depth,max_features,min_samples_leaf,min_samples_split,n_estimators):\n",
        "    model = RandomForestClassifier()\n",
        "\n",
        "    param = {\n",
        "    'max_depth': max_depth,\n",
        "    'max_features': max_features,\n",
        "    'min_samples_leaf': min_samples_leaf,\n",
        "    'min_samples_split': min_samples_split,\n",
        "    'n_estimators': n_estimators\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(model, param_grid = param,cv=3, verbose=True)\n",
        "    grid_search.fit(X_train,y_train)\n",
        "    return grid_search.best_estimator_\n",
        "  \n",
        "\n",
        "def confusionMatrix(y_test,y_pred):\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    pcm = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    pcm.plot()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXqF5U74pN4T"
      },
      "outputs": [],
      "source": [
        "model = ANN(143,3)\n",
        "model.add_layer(416,'tanh',True)\n",
        "model.add_layer(128,'tanh')\n",
        "model.Batch_normalization()\n",
        "model.add_layer(100,'tanh')\n",
        "model.Batch_normalization()\n",
        "model.add_layer(3,'sigmoid')\n",
        "\n",
        "model.summary()\n",
        "model.compile('Adam','sparse_categorical_crossentropy',['accuracy'])\n",
        "model.fit(X_train, y_train, 2, 1000, validation_data=(X_test, y_test))\n",
        "y_pred = model.y_pred(X_test)\n",
        "confusionMatrix(y_test,y_pred)\n",
        "model.save(\"ANN_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XuXXDy_m5Bp",
        "outputId": "7a566e1c-0e6a-4298-d054-a86556e1cfb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_11 (Flatten)        (None, 143)               0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 416)               59904     \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 128)               53376     \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 100)               12900     \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 100)              400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 3)                 303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127,395\n",
            "Trainable params: 126,939\n",
            "Non-trainable params: 456\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1682/1682 [==============================] - 3s 2ms/step - loss: 0.0486 - accuracy: 0.9852\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.048590172082185745, 0.9851916432380676]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded = ANN(143,3)\n",
        "model = loaded.load(\"ANN_model\")\n",
        "model.summary()\n",
        "pred = model.predict(vectorized_pass)\n",
        "model.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge_mPA0AGolH"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(vectorized_pass)\n",
        "model.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wHKhLEbX9tK",
        "outputId": "a839125d-90f7-4169-dfa4-2b31e424026a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RandomForestClassifier\n",
            "\n",
            "95.76001932331246\n",
            "\n",
            "DecisionTreeClassifier\n",
            "\n",
            "90.7972724401256\n",
            "\n",
            "XGBClassifier\n",
            "\n",
            "91.28407127329481\n",
            "Epoch 1/50\n",
            "216/216 [==============================] - 5s 18ms/step - loss: 0.4785 - accuracy: 0.8027 - val_loss: 0.7463 - val_accuracy: 0.5896\n",
            "Epoch 2/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.3645 - accuracy: 0.8589 - val_loss: 0.6299 - val_accuracy: 0.7180\n",
            "Epoch 3/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.2874 - accuracy: 0.8943 - val_loss: 0.7432 - val_accuracy: 0.7203\n",
            "Epoch 4/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.2248 - accuracy: 0.9192 - val_loss: 0.5529 - val_accuracy: 0.7724\n",
            "Epoch 5/50\n",
            "216/216 [==============================] - 5s 22ms/step - loss: 0.1858 - accuracy: 0.9350 - val_loss: 0.4218 - val_accuracy: 0.8274\n",
            "Epoch 6/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.1586 - accuracy: 0.9448 - val_loss: 0.1825 - val_accuracy: 0.9348\n",
            "Epoch 7/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.1378 - accuracy: 0.9529 - val_loss: 0.1527 - val_accuracy: 0.9497\n",
            "Epoch 8/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.1230 - accuracy: 0.9586 - val_loss: 0.1443 - val_accuracy: 0.9517\n",
            "Epoch 9/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.1126 - accuracy: 0.9622 - val_loss: 0.1415 - val_accuracy: 0.9490\n",
            "Epoch 10/50\n",
            "216/216 [==============================] - 5s 24ms/step - loss: 0.1049 - accuracy: 0.9652 - val_loss: 0.1219 - val_accuracy: 0.9570\n",
            "Epoch 11/50\n",
            "216/216 [==============================] - 5s 21ms/step - loss: 0.0963 - accuracy: 0.9679 - val_loss: 0.1032 - val_accuracy: 0.9656\n",
            "Epoch 12/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0909 - accuracy: 0.9702 - val_loss: 0.1128 - val_accuracy: 0.9619\n",
            "Epoch 13/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0840 - accuracy: 0.9722 - val_loss: 0.1045 - val_accuracy: 0.9650\n",
            "Epoch 14/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0811 - accuracy: 0.9737 - val_loss: 0.1221 - val_accuracy: 0.9595\n",
            "Epoch 15/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0767 - accuracy: 0.9754 - val_loss: 0.0994 - val_accuracy: 0.9670\n",
            "Epoch 16/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0698 - accuracy: 0.9777 - val_loss: 0.0938 - val_accuracy: 0.9688\n",
            "Epoch 17/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.0673 - accuracy: 0.9785 - val_loss: 0.0822 - val_accuracy: 0.9726\n",
            "Epoch 18/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0699 - accuracy: 0.9774 - val_loss: 0.0972 - val_accuracy: 0.9676\n",
            "Epoch 19/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0671 - accuracy: 0.9783 - val_loss: 0.0772 - val_accuracy: 0.9738\n",
            "Epoch 20/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.0615 - accuracy: 0.9804 - val_loss: 0.0831 - val_accuracy: 0.9734\n",
            "Epoch 21/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0646 - accuracy: 0.9791 - val_loss: 0.0736 - val_accuracy: 0.9759\n",
            "Epoch 22/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.0875 - val_accuracy: 0.9712\n",
            "Epoch 23/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.0718 - val_accuracy: 0.9771\n",
            "Epoch 24/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0577 - accuracy: 0.9814 - val_loss: 0.0641 - val_accuracy: 0.9792\n",
            "Epoch 25/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0550 - accuracy: 0.9822 - val_loss: 0.1043 - val_accuracy: 0.9640\n",
            "Epoch 26/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.0668 - val_accuracy: 0.9779\n",
            "Epoch 27/50\n",
            "216/216 [==============================] - 4s 20ms/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: 0.0603 - val_accuracy: 0.9808\n",
            "Epoch 28/50\n",
            "216/216 [==============================] - 7s 31ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0614 - val_accuracy: 0.9800\n",
            "Epoch 29/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0520 - accuracy: 0.9833 - val_loss: 0.0666 - val_accuracy: 0.9788\n",
            "Epoch 30/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.0514 - accuracy: 0.9833 - val_loss: 0.0676 - val_accuracy: 0.9779\n",
            "Epoch 31/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
            "Epoch 32/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0477 - accuracy: 0.9846 - val_loss: 0.0626 - val_accuracy: 0.9798\n",
            "Epoch 33/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0470 - accuracy: 0.9847 - val_loss: 0.0620 - val_accuracy: 0.9801\n",
            "Epoch 34/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.0448 - accuracy: 0.9858 - val_loss: 0.0629 - val_accuracy: 0.9801\n",
            "Epoch 35/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.0648 - val_accuracy: 0.9798\n",
            "Epoch 36/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0433 - accuracy: 0.9863 - val_loss: 0.0568 - val_accuracy: 0.9823\n",
            "Epoch 37/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.0439 - accuracy: 0.9856 - val_loss: 0.0603 - val_accuracy: 0.9807\n",
            "Epoch 38/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.0584 - val_accuracy: 0.9816\n",
            "Epoch 39/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.0629 - val_accuracy: 0.9802\n",
            "Epoch 40/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0420 - accuracy: 0.9863 - val_loss: 0.0735 - val_accuracy: 0.9763\n",
            "Epoch 41/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 0.0518 - val_accuracy: 0.9835\n",
            "Epoch 42/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.0543 - val_accuracy: 0.9839\n",
            "Epoch 43/50\n",
            "216/216 [==============================] - 4s 18ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 0.0617 - val_accuracy: 0.9806\n",
            "Epoch 44/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0666 - val_accuracy: 0.9777\n",
            "Epoch 45/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0381 - accuracy: 0.9877 - val_loss: 0.0641 - val_accuracy: 0.9800\n",
            "Epoch 46/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0359 - accuracy: 0.9885 - val_loss: 0.0547 - val_accuracy: 0.9835\n",
            "Epoch 47/50\n",
            "216/216 [==============================] - 4s 19ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0583 - val_accuracy: 0.9813\n",
            "Epoch 48/50\n",
            "216/216 [==============================] - 4s 20ms/step - loss: 0.0368 - accuracy: 0.9880 - val_loss: 0.0596 - val_accuracy: 0.9815\n",
            "Epoch 49/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0349 - accuracy: 0.9886 - val_loss: 0.0535 - val_accuracy: 0.9835\n",
            "Epoch 50/50\n",
            "216/216 [==============================] - 4s 17ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.0498 - val_accuracy: 0.9850\n"
          ]
        }
      ],
      "source": [
        "clf_name = ['RandomForestClassifier','DecisionTreeClassifier','XGBClassifier']\n",
        "clf__ = []\n",
        "clf__.append(RandomForestClassifier(max_depth=61,\n",
        "                                    n_jobs=-1))\n",
        "clf__.append(DecisionTreeClassifier(max_depth=61))\n",
        "clf__.append(XGBClassifier(\n",
        "    learning_rate=0.9,\n",
        "    n_estimators=15,\n",
        "    objective=\"multi:softprob\",\n",
        "    nthread=3))\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('clf', RandomForestClassifier())])\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(clf__)):\n",
        "  model = pipe_model(X_train,y_train,X_test,y_test)\n",
        "  pipeline.set_params(clf = clf__[i])\n",
        "  print(f'\\n{clf_name[i]}\\n')\n",
        "  accuracy  = model.model_score(X_test,y_test)\n",
        "  print(accuracy)\n",
        "  model.save_model(clf_name[i])\n",
        "  y_pred = model.predict(X_test)\n",
        "  confusionMatrix(y_test,y_pred)\n",
        "\n",
        "\n",
        "model = ANN(143,3)\n",
        "model.add_layer(416,'tanh',True)\n",
        "model.add_layer(128,'tanh')\n",
        "model.Batch_normalization()\n",
        "model.add_layer(100,'tanh')\n",
        "model.Batch_normalization()\n",
        "model.add_layer(3,'sigmoid')\n",
        "\n",
        "model.compile('Adam','sparse_categorical_crossentropy',['accuracy'])\n",
        "model.fit(X_train, y_train, 50, 1000, validation_data=(X_test, y_test))\n",
        "y_pred = model.y_pred(X_test)\n",
        "confusionMatrix(y_test,y_pred)\n",
        "model.save(\"ANN_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgLAY24_M85S"
      },
      "outputs": [],
      "source": [
        "for i in range(len(clf_name)):\n",
        "  model = pickle.load(clf_name[i])\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Iv-BvwKQwZ0",
        "outputId": "1a59dd2c-fafd-468a-efba-c72cb5c350bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " RandomForestClassifier \n",
            "\n",
            "[2 2 0 2]\n",
            "\n",
            " DecisionTreeClassifier \n",
            "\n",
            "[2 2 1 2]\n",
            "\n",
            " XGBClassifier \n",
            "\n",
            "[2 2 0 2]\n",
            "\n",
            "Artificial Neural Network\n",
            "\n",
            "[1 2 0 2]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for i in  range(len(clf_name)):\n",
        "  pipeModel = pipe_model(X_train,y_train,X_test,y_test)\n",
        "  model = pipeModel.load(clf_name[i])\n",
        "  predict = model.predict(vectorized_pass)\n",
        "  print(\"\\n\",clf_name[i],\"\\n\")\n",
        "  print(predict)\n",
        "\n",
        "ANNmodel = ANN(143,3)\n",
        "model = ANNmodel.load(\"ANN_model\")\n",
        "print(\"\\nArtificial Neural Network\\n\")\n",
        "predict  = ANNmodel.predict(model,vectorized_pass)\n",
        "\n",
        "print(predict)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03xjtlq1B4P3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoWlvYwGhYRI",
        "outputId": "92cfa792-688e-4740-c634-b89a267855ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('model', DecisionTreeClassifier(max_depth=61))])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = DecisionTreeClassifier()\n",
        "pipe = Pipeline(steps=[\n",
        "                       (\"model\",model)])\n",
        "\n",
        "criterion = ['gini','entropy']\n",
        "max_depth = [i for i in range(1,100,20)]\n",
        "samp_leaf = [1,2]\n",
        "samp_split = [2,3]\n",
        "param = {\"model__criterion\":criterion,\n",
        "         \"model__max_depth\":max_depth,\n",
        "         \"model__min_samples_split\":samp_split,\n",
        "         \"model__min_samples_leaf\":samp_leaf,\n",
        "         }\n",
        "_grid = GridSearchCV(estimator=pipe, param_grid=param, verbose=True)\n",
        "pipe.get_params().keys()\n",
        "_grid.fit(X_train,y_train)\n",
        "_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7nn2P-aKIgo"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "param = {\n",
        " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
        " 'max_features': ['auto', 'sqrt'],\n",
        " 'min_samples_leaf': [1, 2, 4],\n",
        " 'min_samples_split': [2, 3,5, 10],\n",
        " 'n_estimators': [2,3,5,10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid = param,cv=3, verbose=True)\n",
        "grid_search.fit(X_train,y_train)\n",
        "grid_search.best_estimator_"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18YcWyVYjJ1rnDZEdklwRqJSQvLqC32IZ",
      "authorship_tag": "ABX9TyMPGAV9uYiFr3ds5bKAtCPn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}